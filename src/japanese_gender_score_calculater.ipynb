{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4bf60272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MeCab\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import neologdn\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c7b16e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "japaneseMasculineWordsList = open('./data/gendered_words_lists/ja/masculine.json', 'r')\n",
    "japaneseMasculineWords = json.load(japaneseMasculineWordsList)\n",
    "japaneseFeminineWordsList = open('./data/gendered_words_lists/ja/feminine.json', 'r')\n",
    "japaneseFeminineWords = json.load(japaneseFeminineWordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "36395537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of gendered words in each job advertisement\n",
    "dataDirectory = './data/job_advertisements/ja/'\n",
    "# get the list of file names\n",
    "files = [f for f in listdir(dataDirectory) if isfile(join(dataDirectory, f)) and ('failed' not in f)]\n",
    "\n",
    "# declare the dataframe object to save the results\n",
    "df = pd.DataFrame(index=[], columns=['dataIndex', 'occupation', 'masclineWordCount', 'feminineWordCount', 'wordCount'])\n",
    "dfByOccupation = pd.DataFrame(index=[], columns=['occupation', 'masclineWordCount', 'feminineWordCount', 'wordCount'])\n",
    "genderedWordDf = pd.DataFrame(index=[], columns=['word', 'occupation'])\n",
    "\n",
    "# initiate the tagger to parse and clean Japanese sentences\n",
    "tagger = MeCab.Tagger('-d /opt/homebrew/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "tagger.parse('')\n",
    "re_hiragana = re.compile(r'^[あ-ん]+$')\n",
    "\n",
    "dataIndex = 1    \n",
    "for file in files:\n",
    "    # open job advertisements file\n",
    "    jsonOpen = open(dataDirectory + file, 'r')\n",
    "    jobAdvertisements = json.load(jsonOpen)\n",
    "    occupation = file.replace('.json', '')\n",
    "    \n",
    "    masculineWordCounterPerOccupation = 0\n",
    "    feminineWordCounterPerOccupation = 0\n",
    "    wordCounterPerOccupation = 0\n",
    "\n",
    "    getIndex = 1\n",
    "    for jobAdvertisement in jobAdvertisements:\n",
    "        if jobAdvertisement.get(str(getIndex)):\n",
    "            # clean the sentences\n",
    "            cleaned_title = neologdn.normalize(unicodedata.normalize(\"NFKC\", jobAdvertisement[str(getIndex)]['title'].replace(' |\\n', ''))).lower()\n",
    "            cleaned_summary = neologdn.normalize(unicodedata.normalize(\"NFKC\", jobAdvertisement[str(getIndex)]['description_summary'].replace(' |\\n', ''))).lower()\n",
    "            cleaned_detail = neologdn.normalize(unicodedata.normalize(\"NFKC\", jobAdvertisement[str(getIndex)]['description_detail'].replace(' |\\n', ''))).lower()\n",
    "            cleaned_desired_person = neologdn.normalize(unicodedata.normalize(\"NFKC\", jobAdvertisement[str(getIndex)]['desired_person'].replace(' |\\n', ''))).lower()            \n",
    "            all_sentences =  cleaned_title + ' ' + cleaned_summary + ' ' + cleaned_detail + ' ' + cleaned_desired_person \n",
    "                        \n",
    "            masculineWordCounterPerAdvertisement = 0\n",
    "            feminineWordCounterPerAdvertisement = 0\n",
    "            counter = 0\n",
    "            \n",
    "            node = tagger.parseToNode(all_sentences)\n",
    "            while node:\n",
    "                counter += 1\n",
    "                #select specific word types\n",
    "                if node.feature.split(\",\")[0] in  ['名詞', '形容詞', '動詞']:\n",
    "                    if node.feature.split(\",\")[0] == '': \n",
    "                        None\n",
    "                    elif len(node.feature.split(\",\")[6]) == 1: \n",
    "                        None\n",
    "                    elif re_hiragana.fullmatch(node.feature.split(\",\")[6]):\n",
    "                        None\n",
    "                    else: \n",
    "                        for japaneseMasculineWord in japaneseMasculineWords:\n",
    "                            if japaneseMasculineWord == node.feature.split(\",\")[6]:\n",
    "                                dataIndex += 1\n",
    "                                masculineWordCounterPerAdvertisement += 1\n",
    "                                wordData = pd.DataFrame({\n",
    "                                    'word': japaneseMasculineWord,\n",
    "                                    'occupation': occupation,\n",
    "                                }, index=[str(counter)])\n",
    "                                genderedWordDf = pd.concat([genderedWordDf, wordData])\n",
    "                                break\n",
    "                        for japaneseFeminineWord in japaneseFeminineWords:\n",
    "                            if japaneseFeminineWord == node.feature.split(\",\")[6]:\n",
    "                                dataIndex += 1\n",
    "                                feminineWordCounterPerAdvertisement += 1\n",
    "                                wordData = pd.DataFrame({\n",
    "                                    'word': japaneseFeminineWord,\n",
    "                                    'occupation': occupation,\n",
    "                                }, index=[str(counter)])\n",
    "                                genderedWordDf = pd.concat([genderedWordDf, wordData])\n",
    "                                break\n",
    "                else:\n",
    "                    pass\n",
    "                node = node.next\n",
    "            # if masculineNumber == 0 and feminineNumber == 0:\n",
    "            #     x = 0\n",
    "            # else:\n",
    "            #     x = (1/(masculineNumber + feminineNumber)) * (masculineNumber - feminineNumber)\n",
    "            # genderBiasScore = 1 / (1 + math.exp(-x))\n",
    "\n",
    "            record =  pd.DataFrame({\n",
    "                'dataIndex': dataIndex,\n",
    "                'occupation': occupation,\n",
    "                'masclineWordCount': masculineWordCounterPerAdvertisement,\n",
    "                'feminineWordCount': feminineWordCounterPerAdvertisement,\n",
    "                'wordCount': counter\n",
    "            }, index=[str(getIndex)])\n",
    "            df = pd.concat([df, record])\n",
    "            masculineWordCounterPerOccupation += masculineWordCounterPerAdvertisement\n",
    "            feminineWordCounterPerOccupation += feminineWordCounterPerAdvertisement\n",
    "            wordCounterPerOccupation += counter\n",
    "        getIndex += 1\n",
    "\n",
    "    record =  pd.DataFrame({\n",
    "        'occupation': occupation,\n",
    "        'masclineWordCount' : masculineWordCounterPerOccupation,\n",
    "        'feminineWordCount' : feminineWordCounterPerOccupation, \n",
    "        'wordCount' : wordCounterPerOccupation\n",
    "    }, index=[str(dataIndex)])\n",
    "    dfByOccupation = pd.concat([dfByOccupation, record])\n",
    "\n",
    "df.to_csv('./result/japanese_result.csv')\n",
    "dfByOccupation.to_csv('./result/japanese_result_per_occupation.csv')\n",
    "genderedWordDf.to_csv('./result/japanese_gendered_words_in_advertisements.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
