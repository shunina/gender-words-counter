{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71422d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import ConnectionError\n",
    "from http.client import RemoteDisconnected\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import html5lib\n",
    "import json\n",
    "# 最後に削除\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9765d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://next.rikunabi.com/kw%91%E5%8DH/?keywordsearch=1&log_f=1',\n",
    "    'https://next.rikunabi.com/kw%83h%83%89%83C%83o%81%255B/?keywordsearch=1&log_f=1',\n",
    "    'https://next.rikunabi.com/kw%92%CA%90M+%8DH%8E%96/?keywordsearch=1&log_f=1',\n",
    "    'https://next.rikunabi.com/kw%83%255C%83t%83g%83E%83F%83A+%8AJ%94%AD/?keywordsearch=1&log_f=1',\n",
    "    'https://next.rikunabi.com/kw%96%F2%8D%DC%8Et/?keywordsearch=1&log_f=1',\n",
    "    'https://next.rikunabi.com/kw%8E%F3%95t+%88%C4%93%E0/?keywordsearch=1&log_f=1',\n",
    "    'https://next.rikunabi.com/kw%8A%C5%8C%EC%8Et/?keywordsearch=1&log_f=1',\n",
    "    'https://next.rikunabi.com/kw%95%DB%88%E7%8Em/?keywordsearch=1&log_f=1'    \n",
    "    ]\n",
    "fileNames = [\n",
    "    'carpentor',\n",
    "    'driver',\n",
    "    'electrician',\n",
    "    'software_engineer',\n",
    "    'pharmacist',\n",
    "    'secretary',\n",
    "    'nurse',\n",
    "    'childminder'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c08077",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobNumberFinder = 'rnn-pageNumber rnn-textXl'\n",
    "jobTitleFinder = \"rnn-linkText rnn-linkText--black\"\n",
    "jobDetailBaseUrl = \"https://next.rikunabi.com\"\n",
    "jobDetailDescriptionFinder = 'rn3-companyOfferRecruitment__headText'\n",
    "jobDescriptionAndWantedEmployeeFinder = '.rn3-companyOfferRecruitment__text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後に削除\n",
    "import socks,socket\n",
    "user_agent_list = [\n",
    "'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後に削除\n",
    "response = requests.get(\"https://next.rikunabi.com/company/cmi1729260002/nx1_rq0021612896/?fr=cp_s00890&list_disp_no=1&leadtc=keyword_ichiran_cst_n3_ttl\")\n",
    "soup = BeautifulSoup(response.content, 'html5lib')\n",
    "jobNumber = soup.select(jobDescriptionAndWantedEmployeeFinder)\n",
    "\n",
    "print(jobNumber[1].get_text())\n",
    "\n",
    "import socks,socket\n",
    "from urllib.request import urlopen\n",
    "\n",
    "socks.setdefaultproxy(proxy_type=socks.PROXY_TYPE_SOCKS5, addr='127.0.0.1', port=9050)\n",
    "socket.socket = socks.socksocket\n",
    "\n",
    "html = requests.get('http://checkip.dyndns.com/').text\n",
    "print(html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8428712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fileNameindex = 0\n",
    "failedTopUrls = []\n",
    "failedDetailUrls = []\n",
    "errors = []\n",
    "for url in urls:\n",
    "    htmlNumber = 1\n",
    "    data = []\n",
    "    dataIndex = 1\n",
    "    try:\n",
    "        # 最後に削除\n",
    "        socks.setdefaultproxy(proxy_type=socks.PROXY_TYPE_SOCKS5, addr='127.0.0.1', port=9050)\n",
    "        socket.socket = socks.socksocket\n",
    "        headers = {'User-Agent': random.choice(user_agent_list)}\n",
    "        \n",
    "        # 最後に削除\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        # response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "        time.sleep(1)\n",
    "        jobNumber = soup.find(\"span\", class_=jobNumberFinder).get_text()\n",
    "        print(\"Success - url:\" + url + \"jobNumber:\" + jobNumber)\n",
    "    except (RemoteDisconnected, ConnectionError, Exception) as e:\n",
    "        print('Fail - url:' + url)\n",
    "        failedTopUrls.append(url)\n",
    "        errors.append(e)\n",
    "        time.sleep(0.3)\n",
    "        continue\n",
    "    while(True):\n",
    "        if(htmlNumber == 1):\n",
    "            titles = soup.find_all(\"a\", class_=jobTitleFinder)\n",
    "        else:\n",
    "            try:\n",
    "                # 最後に削除\n",
    "                newUrl = url.replace('(?<=\\?)(.*)(?=\\/)', 'crn' + str(htmlNumber) + '.html')\n",
    "                headers = {'User-Agent': random.choice(user_agent_list)}\n",
    "                response = requests.get(newUrl, headers=headers, timeout=10)\n",
    "                # response = requests.get(newUrl)                \n",
    "                time.sleep(1)\n",
    "                soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "                response.close()\n",
    "                titles = soup.find_all(\"a\", class_=jobTitleFinder)\n",
    "            except (RemoteDisconnected, ConnectionError, Exception) as e:\n",
    "                print('Fail - url:' + newUrl)\n",
    "                errors.append(e)\n",
    "                failedTopUrls.append(newUrl)\n",
    "                htmlNumber = htmlNumber + 50\n",
    "                if(htmlNumber - 1 >= int(jobNumber)):\n",
    "                    break\n",
    "                time.sleep(random.randint(2,5))\n",
    "                continue\n",
    "        for title in titles:\n",
    "            try:\n",
    "                # 最後に削除\n",
    "                headers = {'User-Agent': random.choice(user_agent_list)}\n",
    "                jobDetailResponse = requests.get(jobDetailBaseUrl + title['href'], headers=headers, timeout=10)\n",
    "                # jobDetailResponse = requests.get(jobDetailBaseUrl + title['href'])                \n",
    "                time.sleep(1)\n",
    "                jobDetailSoup = BeautifulSoup(jobDetailResponse.content, \"html5lib\")\n",
    "                jobDetailResponse.close()\n",
    "                jobDescriptionSummary = None if jobDetailSoup.find(\"div\", class_=jobDetailDescriptionFinder) is None else jobDetailSoup.find(\"div\", class_=jobDetailDescriptionFinder).get_text()\n",
    "                if jobDescriptionSummary is not None:\n",
    "                    jobDescriptions = jobDetailSoup.select(jobDescriptionAndWantedEmployeeFinder)\n",
    "                    jobDescriptionText = ''\n",
    "                    jobWantedPersonText = ''\n",
    "                    descriptionIndex = 0\n",
    "                    for jobDescription in jobDescriptions:\n",
    "                        if(descriptionIndex == 0):\n",
    "                            jobDescriptionText = jobDescription.get_text()\n",
    "                        elif(descriptionIndex == 1):\n",
    "                            jobWantedPersonText = jobDescription.get_text()\n",
    "                            break\n",
    "                        descriptionIndex = descriptionIndex + 1                    \n",
    "            except (RemoteDisconnected, ConnectionError, Exception) as e:\n",
    "                print('url:' + jobDetailBaseUrl + title['href'])\n",
    "                failedDetailUrls.append(newUrl)\n",
    "                errors.append(e)\n",
    "                continue\n",
    "            if jobDescriptionSummary is None:\n",
    "                try:\n",
    "                    # 最後に削除\n",
    "                    headers = {'User-Agent': random.choice(user_agent_list)}\n",
    "                    jobMoreDetailResponse = requests.get(jobDetailBaseUrl + title['href'].replace('nx1', 'nx2'), headers=headers, timeout=10)\n",
    "                    # jobMoreDetailResponse = requests.get(jobDetailBaseUrl + title['href'].replace('nx1', 'nx2'))\n",
    "                    time.sleep(1)\n",
    "                    jobDetailMoreSoup = BeautifulSoup(jobMoreDetailResponse.content, \"html5lib\")\n",
    "                    jobMoreDetailResponse.close()                \n",
    "                    jobDescriptionSummary = jobDetailMoreSoup.find(\"div\", class_=jobDetailDescriptionFinder).get_text()\n",
    "                    if jobDescriptionSummary is not None:\n",
    "                        jobDescriptions = jobDetailMoreSoup.select(jobDescriptionAndWantedEmployeeFinder)\n",
    "                        jobDescriptionText = ''\n",
    "                        jobWantedPersonText = ''\n",
    "                        descriptionIndex = 0                        \n",
    "                        for jobDescription in jobDescriptions:\n",
    "                            if(descriptionIndex == 0):\n",
    "                                jobDescriptionText = jobDescription.get_text()\n",
    "                            elif(descriptionIndex == 1):\n",
    "                                jobWantedPersonText = jobDescription.get_text()\n",
    "                                break\n",
    "                            descriptionIndex = descriptionIndex + 1                    \n",
    "                except (RemoteDisconnected, ConnectionError, Exception) as e:\n",
    "                    print('url:' + jobDetailBaseUrl + title['href'].replace('nx1', 'nx2'))\n",
    "                    errors.append(e)\n",
    "                    continue\n",
    "                \n",
    "            data.append(\n",
    "                {str(dataIndex) : {\n",
    "                    'title': title.get_text(),\n",
    "                    'description_summary':jobDescriptionSummary,\n",
    "                    'description_detail':jobDescriptionText,\n",
    "                    'desired_person':jobWantedPersonText\n",
    "                    }})\n",
    "            dataIndex = dataIndex + 1\n",
    "            time.sleep(random.randint(2,5))\n",
    "        htmlNumber = htmlNumber + 50\n",
    "        if(htmlNumber - 1 >= int(jobNumber)):\n",
    "            break\n",
    "        time.sleep(random.randint(3,5))\n",
    "    \n",
    "    # export data into json file\n",
    "    with open('./ja/data/' + fileNames[fileNameindex] + '.json', mode='w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "    print(fileNames[fileNameindex] + ':done')\n",
    "    fileNameindex = fileNameindex + 1\n",
    "    \n",
    "# export Top Url data into json file\n",
    "with open('./ja/data/failedTopUrls.json', mode='w', encoding='utf-8') as file:\n",
    "    json.dump(failedTopUrls, file, ensure_ascii=False, indent=2)\n",
    "# export detailed Url data into json file\n",
    "with open('./ja/data/failedDetailUrls.json', mode='w', encoding='utf-8') as file:\n",
    "    json.dump(failedDetailUrls, file, ensure_ascii=False, indent=2)\n",
    "# export error data into json file\n",
    "with open('./ja/data/error.json', mode='w', encoding='utf-8') as file:\n",
    "    json.dump(str(errors), file, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後に削除\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "myDatabase = client['jobAdDB']\n",
    "myCollection = myDatabase['carpentor']\n",
    "myCollection.insert_many(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
